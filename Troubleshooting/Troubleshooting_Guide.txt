# Troubleshooting: EC2 Instance Won't Start

**Problem:** EC2 instance is stuck in "pending" or immediately goes to "stopped" after start attempt

**Last Updated:** December 2024

---

## Quick Checklist

Before diving deep, check these common issues:

- [ ] Is your account in good standing? (Check AWS billing/limits)
- [ ] Are you in the right region? (Check top-right of console)
- [ ] Did you exceed EC2 instance limits? (Service Quotas)
- [ ] Is the instance type available in this AZ? (Try different AZ)
- [ ] Check recent changes (did someone modify security groups/networking?)

---

## Symptom 1: Stuck in "Pending" State

Instance shows "pending" for 5+ minutes and never reaches "running".

### Step 1: Check System Status

```bash
# Get detailed instance status
aws ec2 describe-instance-status --instance-ids i-1234567890abcdef0

# Look for system status checks and instance status checks
```

**What you're looking for:**
- System Status: initializing (normal for first ~2 min)
- Instance Status: initializing (normal for first ~2 min)

If stuck in "initializing" for 5+ minutes, likely a hardware issue on AWS side.

### Step 2: Check CloudWatch Logs

Go to EC2 Console → Instance → Monitoring tab → System Log

Look for boot errors like:
- Kernel panics
- Filesystem errors
- Network configuration issues

**Common patterns I've seen:**
```
[FAILED] Failed to start network service
```
or
```
Kernel panic - not syncing: VFS: Unable to mount root fs
```

### Step 3: Check Instance Capacity

```bash
# See if you're hitting service limits
aws service-quotas get-service-quota \
  --service-code ec2 \
  --quota-code L-1216C47A
```

**What I learned:** Sometimes AWS just doesn't have capacity for that instance type in that AZ. Try:
- Different availability zone
- Different instance type
- Different region (last resort)

### Step 4: Fix - Stop and Modify

If stuck in pending more than 15 minutes:

```bash
# Force stop (even if it says pending)
aws ec2 stop-instances --instance-ids i-1234567890abcdef0 --force

# Wait for it to fully stop
aws ec2 wait instance-stopped --instance-ids i-1234567890abcdef0

# Try starting in different AZ (if using EBS)
# First, get the current subnet
aws ec2 describe-instances --instance-ids i-1234567890abcdef0 \
  --query 'Reservations[0].Instances[0].SubnetId'

# Change to subnet in different AZ
aws ec2 modify-instance-attribute \
  --instance-id i-1234567890abcdef0 \
  --subnet-id subnet-different-az

# Start again
aws ec2 start-instances --instance-ids i-1234567890abcdef0
```

---

## Symptom 2: Starts Then Immediately Stops

Instance goes: pending → running → stopping → stopped (in under 1 minute)

### Root Cause: Usually Instance Status Checks Failing

**Step 1: Check Why It Stopped**

```bash
# Get state transition reason
aws ec2 describe-instances --instance-ids i-1234567890abcdef0 \
  --query 'Reservations[0].Instances[0].StateTransitionReason'
```

Common reasons:
- "Client.UserInitiatedShutdown" - You or a script stopped it
- "Client.InstanceInitiatedShutdown" - Instance shut itself down (check user-data script!)
- "Server.InternalError" - AWS issue, try launching new instance
- "Client.InternalError" - Your configuration issue

### Step 2: Check User Data Script

**This bit me hard once!** My user-data script had a typo that caused the instance to shutdown:

```bash
#!/bin/bash
yum update -y
yum install -y httpd
systemctl start httpd
shutdown now  # OOPS - I meant to write "# shutdown now" (as a comment)
```

**How to check:**
```bash
# Get user data
aws ec2 describe-instance-attribute \
  --instance-id i-1234567890abcdef0 \
  --attribute userData \
  --query 'UserData.Value' --output text | base64 --decode
```

Look for commands like:
- `shutdown`
- `halt`
- `poweroff`
- `exit 1` (in scripts without error handling)

### Step 3: Check Root Volume

If root EBS volume has issues, instance will fail to boot:

```bash
# Check root volume
aws ec2 describe-instances --instance-ids i-1234567890abcdef0 \
  --query 'Reservations[0].Instances[0].BlockDeviceMappings'

# Get volume details
aws ec2 describe-volumes --volume-ids vol-1234567890abcdef0
```

**Check for:**
- Volume State: "available" (good) vs "error" (bad)
- Encrypted: If encrypted, do you have KMS permissions?
- Snapshot: Is the snapshot the volume was created from still available?

**Fix:** Create new instance from AMI, or create new volume from snapshot

---

## Symptom 3: "InsufficientInstanceCapacity" Error

Full error: `We currently do not have sufficient capacity in the Availability Zone you requested`

**This is an AWS capacity issue, not your fault!**

### Immediate Fixes (in order of effort):

**Option 1: Try Different AZ (easiest)**
```bash
# Launch in different AZ in same region
# Just change subnet to one in different AZ
```

**Option 2: Try Different Instance Type**
```bash
# If you tried t2.micro, try t3.micro
# If you tried m5.large, try m5a.large or m5n.large
```

**Option 3: Try Different Region**
```bash
# Last resort - launch in different region
# Remember to check your VPC/subnet exists there
```

**Option 4: Wait and Retry**
- Sometimes capacity frees up in 30 minutes
- Try different times of day (less busy hours)

**What I learned:** This happens more with older instance types (t2) or during AWS events. Switching to t3 usually helps.

---

## Symptom 4: Instance Starts But Can't Connect

Instance shows "running" and status checks pass, but you can't SSH/RDP.

### This is actually a different problem! Quick checks:

**Security Group:**
```bash
# Check security group allows SSH (port 22)
aws ec2 describe-security-groups --group-ids sg-1234567890abcdef0

# Look for:
# IpPermissions with Port 22, Protocol tcp, and your IP in IpRanges
```

**Network ACL:**
```bash
# Check subnet's network ACL
aws ec2 describe-network-acls --filters "Name=association.subnet-id,Values=subnet-1234567890abcdef0"
```

**Public IP:**
```bash
# Does instance have public IP?
aws ec2 describe-instances --instance-ids i-1234567890abcdef0 \
  --query 'Reservations[0].Instances[0].PublicIpAddress'
```

If no public IP and you're trying to connect from internet → won't work!

---

## Real Scenario: What I Debugged Last Week

**Problem:** t2.micro instance wouldn't start after I stopped it for 3 days

**Error:** InsufficientInstanceCapacity

**What I tried:**
1. Stopping and starting (didn't work)
2. Different AZ in same region (didn't work) 
3. Switched to t3.micro (WORKED!)

**Lesson:** Newer generation instance types (t3 vs t2) have better availability. The extra $0.0004/hour is worth not dealing with capacity issues.

**Time spent debugging:** 45 minutes  
**Fix:** 2 minutes to change instance type

---

## Prevention Tips

Based on mistakes I've made:

1. **Test user-data scripts locally first** - Use a test instance, don't wait for production
2. **Use t3 instead of t2** - Better availability, negligible cost difference
3. **Monitor Service Quotas** - Set CloudWatch alarm before hitting limits
4. **Document your instance dependencies** - Security groups, IAM roles, EBS volumes
5. **Keep AMIs updated** - Old AMIs can have boot issues with new instance types

---

## When to Give Up and Launch New Instance

Sometimes it's faster to launch a new instance than debug the old one:

**Launch new instance if:**
- Stuck in pending for 30+ minutes
- Getting consistent InsufficientInstanceCapacity errors
- Root volume is corrupted (check system log for filesystem errors)
- AWS Support confirms hardware issue

**Preserve data by:**
1. Detach EBS data volumes (not root) from old instance
2. Attach to new instance
3. Take snapshot of root volume for forensics

**I learned this the hard way:** Spent 3 hours debugging an instance with corrupted root volume. Should have launched new instance after 30 minutes and moved on.

---

## Useful Commands for Debugging

```bash
# Get detailed instance info
aws ec2 describe-instances --instance-ids i-1234567890abcdef0

# View system log (console output)
aws ec2 get-console-output --instance-id i-1234567890abcdef0

# Check instance status over time
aws ec2 describe-instance-status --instance-ids i-1234567890abcdef0 \
  --include-all-instances

# See state change history (CloudTrail)
aws cloudtrail lookup-events \
  --lookup-attributes AttributeKey=ResourceName,AttributeValue=i-1234567890abcdef0
```

---

## What I'm Still Learning

- How to use EC2 Instance Connect for troubleshooting without SSH keys
- Advanced VPC troubleshooting (VPC Flow Logs)
- When to use EC2 Serial Console for instances that won't boot
- Best practices for automated recovery (AWS Systems Manager)

---

**Sources:**
- AWS EC2 Troubleshooting Documentation
- My own trial-and-error over 2 months
- Stack Overflow threads when I got stuck
- AWS re:Post community answers

*This guide reflects my real experience debugging EC2 issues. Not everything here is "best practice" - it's what actually worked when I was stuck.*